{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyadweep/Learning-Data-Placeholders-for-Open-Set-Recognition/blob/main/dataplaceholder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MJVx26HrrBL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision.transforms import ToPILImage, Grayscale"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform = None, train=True):\n",
        "        self.mnist_data = datasets.MNIST(root=root, train=train, transform=transform, download=True)\n",
        "        self.train = train\n",
        "        self.resize_transform = transforms.Resize((224, 224))\n",
        "\n",
        "        if train:\n",
        "            self.filtered_indices = [idx for idx, label in enumerate(self.mnist_data.targets) if label < 6]\n",
        "        else:\n",
        "            self.filtered_indices = [6 if label >= 6 else label for _, label in self.mnist_data]\n",
        "        #self.transform = transform\n",
        "        #self.to_pil = ToPILImage()\n",
        "        #self.grayscale = Grayscale(num_output_channels=3)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filtered_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            filtered_idx = self.filtered_indices[idx]\n",
        "            image, label = self.mnist_data[filtered_idx]\n",
        "        else:\n",
        "            image, _ = self.mnist_data[idx]\n",
        "            label = self.filtered_indices[idx]\n",
        "\n",
        "\n",
        "\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "s26OsRlLr5j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations\n",
        "#transform = transforms.Compose([transforms.ToTensor()])\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Lambda(lambda x: torch.cat([x, x, x], 0)),\n",
        "                #transforms.Normalize(mean, std),\n",
        "                 ])\n",
        "## train_test dataset\n",
        "train_dataset = CustomMNISTDataset(root='path_to_mnist_dataset12', transform=transform, train=True)\n",
        "test_dataset = CustomMNISTDataset(root='path_to_mnist_dataset12', transform=transform, train=False)\n",
        "\n",
        "\n",
        "## Train_Testest Dataloader\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "6-UhvPS6r_mc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370ff0a6-f480-4e8d-ca0d-b7663bff0634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to path_to_mnist_dataset12/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 322797801.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting path_to_mnist_dataset12/MNIST/raw/train-images-idx3-ubyte.gz to path_to_mnist_dataset12/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to path_to_mnist_dataset12/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 115808502.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting path_to_mnist_dataset12/MNIST/raw/train-labels-idx1-ubyte.gz to path_to_mnist_dataset12/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to path_to_mnist_dataset12/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 97268553.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting path_to_mnist_dataset12/MNIST/raw/t10k-images-idx3-ubyte.gz to path_to_mnist_dataset12/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to path_to_mnist_dataset12/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 20331407.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting path_to_mnist_dataset12/MNIST/raw/t10k-labels-idx1-ubyte.gz to path_to_mnist_dataset12/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import optimizer\n",
        "from torch.distributions import Beta\n",
        "import tempfile\n",
        "import random\n",
        "import os\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "TFj0jZkBsIu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(myModel,self).__init__()\n",
        "    self.feat_extractor = models.resnet18(weights = 'IMAGENET1K_V1')\n",
        "    self.feat_extractor.fc = nn.Identity()\n",
        "    self.classifier = nn.Linear(512,7)\n",
        "  def forward(self,img,label):\n",
        "    feat = self.feat_extractor(img)\n",
        "    feat_new=torch.zeros_like(feat).to(device)\n",
        "    for i in range(img.shape[0]):\n",
        "        #for j in range(5):\n",
        "        lambda_ = Beta(torch.FloatTensor([2]), torch.FloatTensor([2])).sample()\n",
        "        lambda_ = lambda_.to(device)\n",
        "        # batch_j =[]\n",
        "        index1 = random.randint(0, img.shape[0] -1)\n",
        "        index2 = random.randint(0, img.shape[0] - 1)\n",
        "\n",
        "        mixup = lambda_ * feat[index1] + (1 - lambda_) * feat[index2]\n",
        "\n",
        "        feat_new[i,:] = mixup\n",
        "    ####\n",
        "    feat_final = torch.cat((feat,feat_new),axis=0)\n",
        "    prob = self.classifier(feat_final)\n",
        "    return prob\n"
      ],
      "metadata": {
        "id": "L5rh1DAUsDgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "lLO7B2drsP4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = myModel().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "dataloaders = {\n",
        "    'train': train_data_loader,\n",
        "    'val': test_data_loader\n",
        "}\n",
        "dataset_sizes = {\n",
        "    'train': len(train_data_loader),\n",
        "    'val':len(test_data_loader)\n",
        "}\n",
        "\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "GpQGOh9z_Xly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b0e8ee5-62bf-4897-a717-6451af8afd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 208MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "    # print(newlabel.shape)\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with tempfile.TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    newlabel = torch.ones(inputs.shape[0]) * 6\n",
        "                    # print(\"NewLable\",newlabel.shape)\n",
        "\n",
        "                    newlabel = newlabel.to(device)\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        # print(labels.shape)\n",
        "                        # print(newlabel.shape)\n",
        "                        label_update = torch.cat((labels,newlabel),axis = 0).type(torch.LongTensor)\n",
        "                        label_update=label_update.to(device)\n",
        "                        # print(label_update.shape)\n",
        "                        # print(inputs.shape)\n",
        "                        outputs = model(inputs,labels)\n",
        "                        # print(\"outputs\",outputs.shape)\n",
        "\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, label_update)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == label_update.data)\n",
        "                #if phase == 'train':\n",
        "                   # scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / (dataset_sizes[phase]*2*batch_size)\n",
        "                epoch_acc = running_corrects.double() / (dataset_sizes[phase]*2*batch_size)\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ],
      "metadata": {
        "id": "B3zI8vbIsYP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainresult = train_model(model, criterion, optimizer, scheduler, num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al2wRTC8scum",
        "outputId": "02c6298b-1565-43d6-f39f-f99fd8dee6f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.2431 Acc: 0.8214\n",
            "val Loss: 0.2616 Acc: 0.7381\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.1694 Acc: 0.8786\n",
            "val Loss: 0.2671 Acc: 0.7129\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.1605 Acc: 0.8843\n",
            "val Loss: 0.2462 Acc: 0.7306\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.1532 Acc: 0.8890\n",
            "val Loss: 0.2563 Acc: 0.7171\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1480 Acc: 0.8927\n",
            "val Loss: 0.2310 Acc: 0.7456\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1436 Acc: 0.8950\n",
            "val Loss: 0.2599 Acc: 0.7269\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1433 Acc: 0.8961\n",
            "val Loss: 0.2570 Acc: 0.7184\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1420 Acc: 0.8956\n",
            "val Loss: 0.2500 Acc: 0.7069\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1402 Acc: 0.8975\n",
            "val Loss: 0.2629 Acc: 0.6987\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1425 Acc: 0.8949\n",
            "val Loss: 0.2499 Acc: 0.6986\n",
            "\n",
            "Training complete in 8m 14s\n",
            "Best val Acc: 0.745557\n"
          ]
        }
      ]
    }
  ]
}