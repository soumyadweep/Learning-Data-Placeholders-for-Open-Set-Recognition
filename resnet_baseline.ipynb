{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soumyadweep/Learning-Data-Placeholders-for-Open-Set-Recognition/blob/main/resnet_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxvHfIcF7V_t"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torchvision.transforms import ToPILImage, Grayscale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93XzU7Q4eKuB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzqTSmcW7gGt"
      },
      "outputs": [],
      "source": [
        "class CustomMNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform = None, train=True):\n",
        "        self.mnist_data = datasets.MNIST(root=root, train=train, transform=transform, download=True)\n",
        "        self.train = train\n",
        "        self.resize_transform = transforms.Resize((224, 224))\n",
        "\n",
        "        if train:\n",
        "            self.filtered_indices = [idx for idx, label in enumerate(self.mnist_data.targets) if label < 6]\n",
        "        else:\n",
        "            self.filtered_indices = [6 if label >= 6 else label for _, label in self.mnist_data]\n",
        "        #self.transform = transform\n",
        "        #self.to_pil = ToPILImage()\n",
        "        #self.grayscale = Grayscale(num_output_channels=3)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filtered_indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.train:\n",
        "            filtered_idx = self.filtered_indices[idx]\n",
        "            image, label = self.mnist_data[filtered_idx]\n",
        "        else:\n",
        "            image, _ = self.mnist_data[idx]\n",
        "            label = self.filtered_indices[idx]\n",
        "\n",
        "\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lU0zzAWy7kuW"
      },
      "outputs": [],
      "source": [
        "# Define the transformations\n",
        "#transform = transforms.Compose([transforms.ToTensor()])\n",
        "transform = transforms.Compose([\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Lambda(lambda x: torch.cat([x, x, x], 0)),\n",
        "                #transforms.Normalize(mean, std),\n",
        "                 ])\n",
        "## train_test dataset\n",
        "train_dataset = CustomMNISTDataset(root='path_to_mnist_dataset12', transform=transform, train=True)\n",
        "test_dataset = CustomMNISTDataset(root='path_to_mnist_dataset12', transform=transform, train=False)\n",
        "\n",
        "\n",
        "## Train_Testest Dataloader\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeoIv5R974oE"
      },
      "outputs": [],
      "source": [
        "# import torchvision.models as models\n",
        "# resnet18 = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYfWjZ4nd7P4"
      },
      "outputs": [],
      "source": [
        " #import torch.nn as nn\n",
        " #resnet18.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4YDghmaeaAy"
      },
      "outputs": [],
      "source": [
        "class myModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(myModel,self).__init__()\n",
        "    self.feat_extractor = models.resnet18(weights = 'IMAGENET1K_V1')\n",
        "    self.feat_extractor.fc = nn.Identity()\n",
        "    self.classifier = nn.Linear(512,7)\n",
        "  def forward(self,img,label):\n",
        "    feat = self.feat_extractor(img)\n",
        "    ####\n",
        "\n",
        "    ####\n",
        "    prob = self.classifier(feat)\n",
        "    return prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysTd_I_7s5wT"
      },
      "outputs": [],
      "source": [
        "from torch.optim import optimizer\n",
        "import tempfile\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHIcVy7_5F8A"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvEJLqs49diM"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    # Create a temporary directory to save training checkpoints\n",
        "    with tempfile.TemporaryDirectory() as tempdir:\n",
        "        best_model_params_path = os.path.join(tempdir, 'best_model_params.pt')\n",
        "\n",
        "        torch.save(model.state_dict(), best_model_params_path)\n",
        "        best_acc = 0.0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "            print('-' * 10)\n",
        "\n",
        "            # Each epoch has a training and validation phase\n",
        "            for phase in ['train', 'val']:\n",
        "                if phase == 'train':\n",
        "                    model.train()  # Set model to training mode\n",
        "                else:\n",
        "                    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "                running_loss = 0.0\n",
        "                running_corrects = 0\n",
        "\n",
        "                # Iterate over data.\n",
        "                for inputs, labels in dataloaders[phase]:\n",
        "                    inputs = inputs.to(device)\n",
        "                    labels = labels.to(device)\n",
        "\n",
        "                    # zero the parameter gradients\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # forward\n",
        "                    # track history if only in train\n",
        "                    with torch.set_grad_enabled(phase == 'train'):\n",
        "                        outputs = model(inputs,labels)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                        # backward + optimize only if in training phase\n",
        "                        if phase == 'train':\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                    # statistics\n",
        "                    running_loss += loss.item() * inputs.size(0)\n",
        "                    running_corrects += torch.sum(preds == labels.data)\n",
        "                #if phase == 'train':\n",
        "                   # scheduler.step()\n",
        "\n",
        "                epoch_loss = running_loss / (dataset_sizes[phase]*batch_size)\n",
        "                epoch_acc = running_corrects.double() / (dataset_sizes[phase]*batch_size)\n",
        "\n",
        "                print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "                # deep copy the model\n",
        "                if phase == 'val' and epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), best_model_params_path)\n",
        "\n",
        "            print()\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "        print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "        # load best model weights\n",
        "        model.load_state_dict(torch.load(best_model_params_path))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMl2hWHbwvBP"
      },
      "outputs": [],
      "source": [
        "from torch.optim import optimizer\n",
        "import tempfile\n",
        "import os\n",
        "model = myModel().to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "dataloaders = {\n",
        "    'train': train_data_loader,\n",
        "    'val': test_data_loader\n",
        "}\n",
        "dataset_sizes = {\n",
        "    'train': len(train_data_loader),\n",
        "    'val':len(test_data_loader)\n",
        "}\n",
        "\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hRaMAcz37kaq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s30jMy5s6Y6K",
        "outputId": "8cd3294b-2049-4071-b1e2-dd822aea7e28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 0.0997 Acc: 0.9686\n",
            "val Loss: 2.8458 Acc: 0.5991\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.0222 Acc: 0.9935\n",
            "val Loss: 3.0185 Acc: 0.5977\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.0209 Acc: 0.9942\n",
            "val Loss: 3.0029 Acc: 0.6003\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.0159 Acc: 0.9953\n",
            "val Loss: 3.1236 Acc: 0.6009\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.0119 Acc: 0.9963\n",
            "val Loss: 3.2548 Acc: 0.6011\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.0093 Acc: 0.9967\n",
            "val Loss: 3.5846 Acc: 0.5997\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.0093 Acc: 0.9969\n",
            "val Loss: 3.7193 Acc: 0.6001\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.0137 Acc: 0.9965\n",
            "val Loss: 3.5659 Acc: 0.5996\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.0072 Acc: 0.9975\n",
            "val Loss: 3.8394 Acc: 0.6009\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.0049 Acc: 0.9983\n",
            "val Loss: 4.1165 Acc: 0.5998\n",
            "\n",
            "Training complete in 4m 15s\n",
            "Best val Acc: 0.601138\n"
          ]
        }
      ],
      "source": [
        "trainresult = train_model(model, criterion, optimizer, scheduler, num_epochs=10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMp2LGHuI+miXxJ795ERhWw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}